description: |
  Deploys a previously released version of the snyk-operator.
  Subsequently upgrades the Operator with a new version that is intended
  to be released. If the Operator reaches the running state in both cases,
  we can aassume that it's able to upgrade.

executor: redhat-openshift/default

working_directory: ~/kubernetes-monitor

steps:
  - checkout

  - run:
      name: Install required packages
      command: |
        sudo apt update
        sudo apt install -y uuid-runtime make
        python -m pip install requests pyyaml
        python scripts/operator/download_operator_sdk.py
        # The machine executor uses an old debian version, the latest OPM 1.16.1 requires a later version of GLIBC that the current machine cannot have.
        # So instead of using the (currently) latest version, we have to use an older one that references an older GLIBC.
        OPM_VERSION=v1.13.0 python scripts/operator/download_operator_package_manager.py
        curl -L https://github.com/openshift/okd/releases/download/4.7.0-0.okd-2021-03-28-152009/openshift-client-linux-4.7.0-0.okd-2021-03-28-152009.tar.gz | tar xfz - -- oc
        sudo mv oc /usr/local/bin/oc
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

  - install_python_requests

  - setup_remote_docker
  - run: docker login --username ${DOCKERHUB_USER} --password ${DOCKERHUB_PASSWORD}

  - run:
      name: Login and update KUBECONFIG
      command: |
        oc login --token="${OPENSHIFT4_PASSWORD}" --server="${OPENSHIFT4_CLUSTER_URL}" --kubeconfig="$(pwd)/kubeconfig"
        echo "export KUBECONFIG=$(pwd)/kubeconfig" >> $BASH_ENV

  - run:
      name: Get last released Operator version
      command: |
        source $BASH_ENV
        set -xeo pipefail

        OPERATOR_VERSION=$(python ./scripts/operator/get_last_published_operator_version.py)

        echo "Currently released version is: ${OPERATOR_VERSION}"
        echo "export OPERATOR_VERSION=${OPERATOR_VERSION}" >> $BASH_ENV

  - run:
      name: Get latest snyk-monitor tag
      description: |
        This tag is used to identify the Operator version we are going to upgrade to.
      command: |
        source $BASH_ENV
        LATEST_TAG_WITH_V=`git describe --abbrev=0 --tags ${CIRCLE_SHA1}`
        LATEST_TAG=${LATEST_TAG_WITH_V:1}
        echo "export LATEST_TAG=${LATEST_TAG}" >> $BASH_ENV

  - run:
      name: End tests early if no new Operator is to be released
      command: |
        source $BASH_ENV
        if [[ "${LATEST_TAG}" == "${OPERATOR_VERSION}" ]]; then
          echo "export NOTHING_TO_TEST=true" >> $BASH_ENV
          exit 1
        fi

  - run:
      name: Package Operator Bundle and push to Docker Hub
      description: |
        Even though the Operator is released to the community-operators repo,
        we can reproduce it locally using our packaged scripts. This also helps us
        test the upgrade by pushing all tested Operators to our Quay repo.
      command: |
        source $BASH_ENV
        set -xeo pipefail

        # Package Operator Bundle to be uploaded to Docker Hub
        SNYK_OPERATOR_IMAGE_TAG=${OPERATOR_VERSION}
        SNYK_MONITOR_IMAGE_TAG=${OPERATOR_VERSION}
        OPERATOR_DIR=$(python scripts/operator/package_operator_bundle.py $OPERATOR_VERSION $SNYK_OPERATOR_IMAGE_TAG $SNYK_MONITOR_IMAGE_TAG)

        python scripts/operator/create_operator_bundle_and_index_and_push.py $OPERATOR_DIR $OPERATOR_VERSION $DOCKERHUB_USER $DOCKERHUB_PASSWORD

  - run:
      name: Remove existing cluster resources if present
      command: |
        set +e
        kubectl patch customresourcedefinition snykmonitors.charts.helm.k8s.io -p '{"metadata":{"finalizers":[]}}' --type=merge -n snyk-monitor
        kubectl patch snykmonitors.charts.helm.k8s.io snyk-monitor -p '{"metadata":{"finalizers":[]}}' --type=merge -n snyk-monitor
        kubectl delete customresourcedefinition snykmonitors.charts.helm.k8s.io
        kubectl delete catalogsource snyk-operator -n openshift-marketplace
        kubectl delete clusterrolebinding snyk-monitor
        kubectl delete clusterrole snyk-monitor
        kubectl delete namespace services
        kubectl delete namespace snyk-monitor
        # Force a success status code, otherwise Bash will implicitly return the last command's code, which can be 1.
        true

  - run:
      name: Configure snyk-monitor namespace
      command: |
        set -xo pipefail
        set +e

        ns=$(kubectl get ns snyk-monitor --no-headers --output=go-template={{.metadata.name}} 2>/dev/null)

        if [[ -z "${ns}" ]]; then
          echo "snyk-monitor namespace not found, creating..."
          kubectl create ns snyk-monitor
        fi

        set -e
        INTEGRATION_ID=$(uuidgen)
        kubectl create secret generic snyk-monitor -n snyk-monitor --from-literal=integrationId=${INTEGRATION_ID} --from-literal=dockercfg.json={}

  - run:
      name: Install Operator
      command: |
        source $BASH_ENV
        set -xe

        sed -i.bak "s|TAG_OVERRIDE|${OPERATOR_VERSION}|g" ./test/fixtures/operator/catalog-source.yaml
        kubectl apply -f ./test/fixtures/operator/catalog-source.yaml

        kubectl apply -f ./test/fixtures/operator/installation.yaml
        sleep 120
        kubectl get pods -n snyk-monitor --no-headers | \
          grep "snyk-operator" | \
          awk 'END { if (NR==0) exit 1; else print $1 }' | \
          xargs -I{} kubectl wait pod/{} -n snyk-monitor --timeout 60s --for condition=Ready

  - run:
      name: Deploy snyk-monitor resource
      command: |
        set -o pipefail

        kubectl apply -f ./test/fixtures/operator/custom-resource.yaml
        sleep 120

        kubectl get pods -n snyk-monitor --no-headers | \
          grep "snyk-monitor" | \
          awk 'END { if (NR==0) exit 1; else print $1 }' | \
          xargs -I{} kubectl wait pod/{} -n snyk-monitor --timeout 60s --for condition=Ready

  - run:
      name: Package Operator Bundle upgrade and push to Docker Hub
      description: Now we are testing that any upgrades to the Operator are detected and applied in the cluster.
      command: |
        source $BASH_ENV
        set -eo pipefail

        REPLACES_VERSION=${OPERATOR_VERSION}

        OPERATOR_DIR=$(python scripts/operator/package_operator_bundle.py "${LATEST_TAG}" "${LATEST_TAG}" "${LATEST_TAG}" "${REPLACES_VERSION}")
        python scripts/operator/create_operator_bundle_and_index_and_push.py $OPERATOR_DIR $LATEST_TAG $DOCKERHUB_USER $DOCKERHUB_PASSWORD $REPLACES_VERSION

  - run:
      name: Upgrade Operator and check that snyk-monitor also upgraded
      command: |
        source $BASH_ENV
        set -xeo pipefail

        # Replace the catalog source with the latest bundled version of snyk-monitor, this is what initiates the upgrade
        sed -i.bak "s|${OPERATOR_VERSION}|${LATEST_TAG}|g" ./test/fixtures/operator/catalog-source.yaml
        kubectl apply -f ./test/fixtures/operator/catalog-source.yaml

        ATTEMPTS=120
        SLEEP_SECONDS_BETWEEN_ATTEMPTS=5
        # total = 10 minutes wait time

        # Periodically poll if the snyk-monitor has upgraded
        for (( attempt=1; attempt<ATTEMPTS; attempt++))
        do
          # Grab the tag of the snyk-monitor container image. If snyk-monitor is not deployed for some reason, we exit immediately.
          VERSION=$(kubectl get pods -n snyk-monitor --no-headers | \
            grep "snyk-monitor" | \
            awk 'END { if (NR==0) exit 1; else print $1 }' | \
            xargs -I{} kubectl get pod {} -n snyk-monitor -o jsonpath={..containers[*].image} | \
            awk '{print $1}' | grep -oE "[0-9]{1}\.[0-9]{1,2}\.[0-9]{1,3}$")

          # Break out of the polling if the tag matches the one we want to upgrade to.
          if [[ "${VERSION}" == "${LATEST_TAG}" ]]; then
            break
          fi

          # Otherwise keep polling
          sleep $SLEEP_SECONDS_BETWEEN_ATTEMPTS
        done

        SNYK_MONITOR_POD=$(kubectl get pods -n snyk-monitor --no-headers | \
          grep "snyk-monitor" | \
          awk 'END { if (NR==0) exit 1; else print $1 }')

        # If we polled for 5 minutes and the snyk-monitor still hasn't upgraded, fail the current job.
        if [[ "${VERSION}" != "${LATEST_TAG}" ]]; then
          &>2 echo "versions (${VERSION}) does not match expected (${LATEST_TAG})!"

          kubectl describe pod ${SNYK_MONITOR_POD} -n snyk-monitor
          kubectl describe catalogsource snyk-operator -n openshift-marketplace
          kubectl get snykmonitors.charts.helm.k8s.io -n snyk-monitor -o yaml

          exit 1
        fi

        # We need to wait for the Pod to become Ready
        kubectl wait pod/${SNYK_MONITOR_POD} -n snyk-monitor --timeout 120s --for condition=Ready

        echo "Update complete!"

  - run:
      name: Notify Slack on successful upgrade
      command: |
        source $BASH_ENV
        ./scripts/slack/notify_success_openshift_upgrade.py "${OPERATOR_VERSION}" "${LATEST_TAG}"

  - run:
      name: Cleanup
      command: |
        set +e

        kubectl delete -f ./test/fixtures/operator/catalog-source.yaml
        kubectl delete -f ./test/fixtures/operator/installation.yaml

        kubectl patch customresourcedefinition snykmonitors.charts.helm.k8s.io -p '{"metadata":{"finalizers":[]}}' --type=merge -n snyk-monitor
        kubectl patch snykmonitors.charts.helm.k8s.io snyk-monitor -p '{"metadata":{"finalizers":[]}}' --type=merge -n snyk-monitor
        kubectl delete -f ./test/fixtures/operator/custom-resource.yaml
        kubectl delete clusterrolebinding snyk-monitor
        kubectl delete clusterrole snyk-monitor

        kubectl delete ns snyk-monitor
        # Force a success status code, otherwise Bash will implicitly return the last command's code, which can be 1.
        true
      when: always

  - run:
      name: Notify Slack on failure
      command: |
        if [[ "${NOTHING_TO_TEST}" != "true" ]]; then
          ./scripts/slack/notify_failure.py "${CIRCLE_BRANCH}" "${CIRCLE_JOB}" "${CIRCLE_BUILD_URL}" "${CIRCLE_PULL_REQUEST}" "${SLACK_WEBHOOK}"
        fi
      when: on_fail
