commands:
  install_python_requests:
    description: Install requests library
    steps:
    - run:
        command: |
          sudo apt update
          sudo apt install python3-requests
        when: always
  setup_node12:
    description: Setup Node 12
    steps:
    - run:
        command: |
          export NVM_DIR="/opt/circleci/.nvm"
          [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
          nvm install v12
          npm install
          echo 'export NVM_DIR="/opt/circleci/.nvm"' >> $BASH_ENV
          echo '[ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"' >> $BASH_ENV
          echo 'nvm use 12' >> $BASH_ENV
jobs:
  build_image:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - install_python_requests
    - run:
        command: |
          docker login --username ${DOCKERHUB_USER} --password ${DOCKERHUB_PASSWORD} &&
          export IMAGE_TAG=$([[ "$CIRCLE_BRANCH" == "staging" ]] && echo "staging-candidate" || echo "discardable") &&
          IMAGE_NAME_CANDIDATE=snyk/kubernetes-monitor:${IMAGE_TAG}-${CIRCLE_SHA1} &&
          ./scripts/docker/build-image.sh ${IMAGE_NAME_CANDIDATE} &&
          docker push ${IMAGE_NAME_CANDIDATE}
        name: Build image
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-build-image-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  build_operator:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - install_python_requests
    - run:
        command: |
          RELEASE_VERSION=v0.15.1
          DOWNLOAD_LOCATION=./operator-sdk
          CURL_FOLLOW_REDIRECTS="-L"
          curl ${CURL_FOLLOW_REDIRECTS} https://github.com/operator-framework/operator-sdk/releases/download/${RELEASE_VERSION}/operator-sdk-${RELEASE_VERSION}-x86_64-linux-gnu -o ${DOWNLOAD_LOCATION}
          chmod +x ${DOWNLOAD_LOCATION}
        name: Download Operator SDK
    - run:
        command: |
          export IMAGE_TAG=$([[ "$CIRCLE_BRANCH" == "staging" ]] && echo "staging-candidate" || echo "discardable")
          ./scripts/operator/create-operator-and-push.sh "${IMAGE_TAG}-${CIRCLE_SHA1}"
        name: Create Operator and push Operator image to DockerHub
    - run:
        command: |
          export IMAGE_TAG=$([[ "$CIRCLE_BRANCH" == "staging" ]] && echo "staging-candidate" || echo "discardable")
          export SNYK_MONITOR_IMAGE_TAG="${IMAGE_TAG}-${CIRCLE_SHA1}"
          export SNYK_OPERATOR_VERSION="0.0.1-${CIRCLE_SHA1}"
          export SNYK_OPERATOR_IMAGE_TAG="${SNYK_MONITOR_IMAGE_TAG}"
          ./scripts/operator/package-operator.sh "${SNYK_OPERATOR_VERSION}" "${SNYK_OPERATOR_IMAGE_TAG}" "${SNYK_MONITOR_IMAGE_TAG}"
        name: Package Operator
    - run:
        command: |
          rm -rf snyk-operator/deploy/olm-catalog/snyk-operator/0.0.0
        name: Remove templated Operator before persisting to workspace
    - persist_to_workspace:
        paths:
        - deploy/olm-catalog/snyk-operator
        root: snyk-operator
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-build-operator-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  deploy_dev:
    docker:
    - image: circleci/node:12
    steps:
    - checkout
    - install_python_requests
    - run:
        command: |
          LATEST_TAG_WITH_V=`git describe --abbrev=0 --tags ${CIRCLE_SHA1}` &&
          LATEST_TAG=${LATEST_TAG_WITH_V:1}-approved &&
          ./scripts/slack/notify_deploy.py $LATEST_TAG dev &&
          curl -i -H "Accept: application/json" -H "Content-Type: application/json" \
              -X POST -d "{\"docker_sha\":\"${LATEST_TAG}\", \
                            \"commit_hash\":\"${CIRCLE_SHA1}\"}" \
              https://my.dev.snyk.io/${DEV_DEPLOY_TOKEN}
        name: Deploy to dev
    - run:
        command: ./scripts/slack/notify_failure.py "deploy-dev"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  deploy_prod:
    docker:
    - image: circleci/node:12
    steps:
    - checkout
    - install_python_requests
    - run:
        command: |
          LATEST_TAG_WITH_V=`git describe --abbrev=0 --tags ${CIRCLE_SHA1}` &&
          LATEST_TAG=${LATEST_TAG_WITH_V:1} &&
          ./scripts/slack/notify_deploy.py $LATEST_TAG prod &&
          curl -i -H "Accept: application/json" -H "Content-Type: application/json" \
              -X POST -d "{}" \
              https://my.prod.snyk.io/${PROD_DEPLOY_TOKEN}
        name: Deploy to prod
    - run:
        command: ./scripts/slack/notify_failure.py "deploy-prod"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  eks_integration_tests:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - install_python_requests
    - run:
        command: mkdir -p /tmp/logs/test/integration/eks
        name: Create temp dir for logs
    - run:
        command: |
          export NVM_DIR="/opt/circleci/.nvm"
          [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
          nvm install v12
          npm install
          export KUBERNETES_MONITOR_IMAGE_NAME_AND_TAG=$(./scripts/circleci-jobs/setup-integration-tests.py)
          .circleci/do-exclusively --branch staging --job ${CIRCLE_JOB} npm run test:integration:eks:yaml
        name: Integration tests EKS
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-eks-integration-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    - store_artifacts:
        path: /tmp/logs/test/integration/eks
    working_directory: ~/kubernetes-monitor
  integration_tests:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - setup_node12
    - install_python_requests
    - run:
        command: mkdir -p /tmp/logs/test/integration/kind
        name: create temp dir for logs
    - run:
        command: |
          export KUBERNETES_MONITOR_IMAGE_NAME_AND_TAG=$(./scripts/circleci-jobs/setup-integration-tests.py)
          npm run test:integration:kind:yaml
        name: Integration tests
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-integration-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    - store_artifacts:
        path: /tmp/logs/test/integration/kind
    working_directory: ~/kubernetes-monitor
  integration_tests_helm:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - setup_node12
    - install_python_requests
    - run:
        command: mkdir -p /tmp/logs/test/integration/kind-helm
        name: Create temporary directory for logs
    - run:
        command: |
          export KUBERNETES_MONITOR_IMAGE_NAME_AND_TAG=$(./scripts/circleci-jobs/setup-integration-tests.py)
          npm run test:integration:kind:helm
        name: Integration tests with Helm deployment
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-integration-helm-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    - store_artifacts:
        path: /tmp/logs/test/integration/kind-helm
    working_directory: ~/kubernetes-monitor
  integration_tests_proxy:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - setup_node12
    - install_python_requests
    - run:
        command: mkdir -p /tmp/logs/test/integration/proxy
        name: Create temporary directory for logs
    - run:
        command: |
          export KUBERNETES_MONITOR_IMAGE_NAME_AND_TAG=$(./scripts/circleci-jobs/setup-integration-tests.py)
          npm run test:integration:kind:proxy
        name: Integration tests with Helm deployment
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-integration-proxy-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    - store_artifacts:
        path: /tmp/logs/test/integration/proxy
    working_directory: ~/kubernetes-monitor
  openshift3_integration_tests:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - setup_node12
    - install_python_requests
    - run:
        command: mkdir -p /tmp/logs/test/integration/openshift3
        name: Create temporary directory for logs
    - run:
        command: |
          export KUBERNETES_MONITOR_IMAGE_NAME_AND_TAG=$(./scripts/circleci-jobs/setup-integration-tests.py)
          npm run test:integration:openshift3:yaml
        name: Integration tests OpenShift 3
    - run:
        command: ./scripts/slack/notify_failure.py "staging-openshift3-integration-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    - store_artifacts:
        path: /tmp/logs/test/integration/openshift3
    working_directory: ~/kubernetes-monitor
  openshift4_integration_tests:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - setup_node12
    - install_python_requests
    - run:
        command: mkdir -p /tmp/logs/test/integration/openshift4
        name: create temp dir for logs
    - run:
        command: |
          echo "${OPENSHIFT4_ETC_HOSTS_ENTRY}" | sudo tee -a /etc/hosts
        name: Append an entry to the test environment to /etc/hosts
    - run:
        command: |
          export KUBERNETES_MONITOR_IMAGE_NAME_AND_TAG=$(./scripts/circleci-jobs/setup-integration-tests.py)
          .circleci/do-exclusively --branch staging --job ${CIRCLE_JOB} npm run test:integration:openshift4:operator
        name: Integration tests OpenShift 4
    - run:
        command: |
          ./scripts/operator/delete-operator-from-quay.sh
        name: Delete Operator from Quay
        when: always
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-openshift4-integration-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    - store_artifacts:
        path: /tmp/logs/test/integration/openshift4
    working_directory: ~/kubernetes-monitor
  operator_upgrade_tests:
    description: |
      Deploys a previously released version of the snyk-operator.
      Subsequently upgrades the Operator with a new version that is intended
      to be released. If the Operator reaches the running state in both cases,
      we can aassume that it's able to upgrade.
    executor: redhat-openshift/default
    steps:
    - checkout
    - run:
        command: |
          sudo apt install -y uuid-runtime
          python -m pip install requests pyyaml
          python -m pip install operator-courier
        name: Install required packages
    - run:
        command: echo "${OPENSHIFT4_ETC_HOSTS_ENTRY}" | sudo tee -a /etc/hosts
        description: "The test cluster returns URLs that are local only to the cluster
          (e.g. https://api.crc.testing).\nThese URLs don't make sense for the public
          internet, so we add a little hack in /etc/hosts \nthat makes the URLs point
          to the IP address of the test cluster, allowing us to reach back to it.\n"
        name: Update /etc/hosts with an entry to the OpenShift cluster
    - redhat-openshift/login-and-update-kubeconfig:
        insecure-skip-tls-verify: true
        openshift-platform-version: 4.x
        password: $OPENSHIFT4_PASSWORD
        server-address: $OPENSHIFT4_CLUSTER_URL
        username: $OPENSHIFT4_USER
    - run:
        command: |
          set -xeo pipefail

          OPERATOR_VERSION=$(python ./scripts/operator/get-last-published-operator-version.py)

          echo "Currently released version is: ${OPERATOR_VERSION}"
          echo "export OPERATOR_VERSION=${OPERATOR_VERSION}" >> $BASH_ENV
        name: Get last released Operator version
    - run:
        command: |
          set -xeo pipefail

          # Package Operator to be uploaded to Quay.io
          SNYK_OPERATOR_IMAGE_TAG=${OPERATOR_VERSION}
          SNYK_MONITOR_IMAGE_TAG=${OPERATOR_VERSION}
          ./scripts/operator/package-operator.sh $OPERATOR_VERSION $SNYK_OPERATOR_IMAGE_TAG $SNYK_MONITOR_IMAGE_TAG

          # We do not want to include the templating files when we push the Operator,
          # therefore we move the directory to /temp, and restore it later
          mkdir temp
          mv ./snyk-operator/deploy/olm-catalog/snyk-operator/0.0.0 ./temp/
        description: |
          Even though the Operator is released to the community-operators repo,
          we can reproduce it locally using our packaged scripts. This also helps us
          test the upgrade by pushing all tested Operators to our Quay repo.
        name: Package and deploy last released Operator
    - run:
        command: |
          set -eo pipefail


          export QUAY_TOKEN=$(curl -H "Content-Type: application/json" \
            -XPOST https://quay.io/cnr/api/v1/users/login \
            -d "{\"user\": {\"username\": \"${QUAY_USERNAME}\", \"password\": \"${QUAY_PASSWORD}\"}}" \
            | jq -r .token)

          OPERATOR_DIR=./snyk-operator/deploy/olm-catalog/snyk-operator/
          QUAY_NAMESPACE=snyk-runtime
          PACKAGE_NAME=snyk-operator

          operator-courier push "${OPERATOR_DIR}" "${QUAY_NAMESPACE}" "${PACKAGE_NAME}" "${OPERATOR_VERSION}" "${QUAY_TOKEN}"
        name: Push Operator to Quay
    - run:
        command: |
          set -xo pipefail
          set +e

          ns=$(kubectl get ns snyk-monitor --no-headers --output=go-template={{.metadata.name}} 2>/dev/null)

          if [[ -z "${ns}" ]]; then
            echo "snyk-monitor namespace not found, creating..."
            kubectl create ns snyk-monitor
          fi

          set -e
          INTEGRATION_ID=$(uuidgen)
          kubectl create secret generic snyk-monitor -n snyk-monitor --from-literal=integrationId=${INTEGRATION_ID} --from-literal=dockercfg.json={}
        name: Configure snyk-monitor namespace
    - run:
        command: |
          set -xe

          kubectl apply -f ./test/fixtures/operator/operator-source.yaml

          set +e
          opsrc=$(kubectl get operatorsource snyk-operator -n openshift-marketplace --no-headers 2>/dev/null | awk '{print $9}')

          set -e
          while [[ "${opsrc}" != "Succeeded" ]]; do
            if [[ -z "${opsrc}" || "${opsrc}" == "Failed" ]]; then
              >&2 echo "failed to deploy operator source resource"
              exit 1
            fi
            opsrc=$(kubectl get operatorsource snyk-operator -n openshift-marketplace --no-headers 2>/dev/null | awk '{print $9}')
          done

          kubectl apply -f ./test/fixtures/operator/installation.yaml
          sleep 60
          kubectl get pods -n snyk-monitor --no-headers | \
            grep "snyk-operator" | \
            awk 'END { if (NR==0) exit 1; else print $1 }' | \
            xargs -I{} kubectl wait pod/{} -n snyk-monitor --timeout 60s --for condition=Ready
        name: Install Operator
    - run:
        command: |
          set -o pipefail

          kubectl apply -f ./test/fixtures/operator/custom-resource.yaml
          sleep 30

          kubectl get pods -n snyk-monitor --no-headers | \
            grep "snyk-monitor" | \
            awk 'END { if (NR==0) exit 1; else print $1 }' | \
            xargs -I{} kubectl wait pod/{} -n snyk-monitor --timeout 60s --for condition=Ready
        name: Deploy snyk-monitor resource
    - run:
        command: |
          set -xeo pipefail

          mv ./temp/0.0.0 ./snyk-operator/deploy/olm-catalog/snyk-operator/
          rm -rf ./snyk-operator/deploy/olm-catalog/snyk-operator/${OPERATOR_VERSION}
        name: Restore template files
    - run:
        command: |
          set -eo pipefail

          LATEST_TAG_WITH_V=`git describe --abbrev=0 --tags ${CIRCLE_SHA1}`
          LATEST_TAG=${LATEST_TAG_WITH_V:1}

          REPLACES_VERSION=${OPERATOR_VERSION}

          CSV_LOCATION="./snyk-operator/deploy/olm-catalog/snyk-operator"
          OPERATOR_PACKAGE_YAML_LOCATION="${CSV_LOCATION}/snyk-operator.package.yaml"
          sed -i.bak "s|${REPLACES_VERSION}|${LATEST_TAG}|g" "${OPERATOR_PACKAGE_YAML_LOCATION}"

          ./scripts/operator/package-operator.sh ${LATEST_TAG} ${LATEST_TAG} ${LATEST_TAG} ${REPLACES_VERSION}

          mv ./snyk-operator/deploy/olm-catalog/snyk-operator/0.0.0 ./temp/

          export QUAY_TOKEN=$(curl -H "Content-Type: application/json" \
            -XPOST https://quay.io/cnr/api/v1/users/login \
            -d "{\"user\": {\"username\": \"${QUAY_USERNAME}\", \"password\": \"${QUAY_PASSWORD}\"}}" \
            | jq -r .token)

          OPERATOR_DIR=./snyk-operator/deploy/olm-catalog/snyk-operator/
          QUAY_NAMESPACE=snyk-runtime
          PACKAGE_NAME=snyk-operator

          set +x
          operator-courier push "${OPERATOR_DIR}" "${QUAY_NAMESPACE}" "${PACKAGE_NAME}" "${LATEST_TAG}" "${QUAY_TOKEN}"
          set -x
          echo "export LATEST_TAG=${LATEST_TAG}" >> $BASH_ENV
        name: Package Operator upgrade and push to Quay
    - run:
        command: |
          set -xeo pipefail

          # NOTE: This is the action that actually refreshes the source and makes OLM "see" the new version in Quay!
          oc patch operatorsource snyk-operator -n openshift-marketplace -p '[{"op":"replace","path":"/status","value":{}}]' --type json
          sleep 120

          VERSION=$(kubectl get pods -n snyk-monitor --no-headers | \
            grep "snyk-monitor" | \
            awk 'END { if (NR==0) exit 1; else print $1 }' | \
            xargs -I{} kubectl get pod {} -n snyk-monitor -o jsonpath={..image} | \
            awk '{print $1}' | grep -oE "[0-9]{1}\.[0-9]{1,2}\.[0-9]{1,3}$")

          if [[ "${VERSION}" != "${LATEST_TAG}" ]]; then
            &>2 echo "versions (${VERSION}) does not match expected (${LATEST_TAG})!"
            exit 1
          fi

          echo "Update complete!"
        name: Upgrade Operator and check that snyk-monitor also upgraded
    - run:
        command: |
          set +e

          curl -XDELETE -H "Accept: application/json" -H "Content-Type: application/json" \
            -H "Authorization: ${QUAY_DELETE_TOKEN}" "https://quay.io/cnr/api/v1/packages/snyk-runtime/snyk-operator/${OPERATOR_VERSION}/helm"
          curl -XDELETE -H "Accept: application/json" -H "Content-Type: application/json" \
            -H "Authorization: ${QUAY_DELETE_TOKEN}" "https://quay.io/cnr/api/v1/packages/snyk-runtime/snyk-operator/${LATEST_TAG}/helm"

          kubectl delete -f ./test/fixtures/operator/operator-source.yaml
          kubectl delete -f ./test/fixtures/operator/installation.yaml

          kubectl patch customresourcedefinition snykmonitors.charts.helm.k8s.io -p '{"metadata":{"finalizers":[]}}' --type=merge -n snyk-monitor
          kubectl patch snykmonitors.charts.helm.k8s.io snyk-monitor -p '{"metadata":{"finalizers":[]}}' --type=merge -n snyk-monitor
          kubectl delete -f ./test/fixtures/operator/custom-resource.yaml
          kubectl delete clusterrolebinding snyk-monitor
          kubectl delete clusterrole snyk-monitor

          kubectl delete ns snyk-monitor
        name: Cleanup
        when: always
    working_directory: ~/kubernetes-monitor
  publish:
    docker:
    - image: circleci/node:12
    steps:
    - checkout
    - setup_remote_docker
    - install_python_requests
    - run:
        command: |
          LATEST_TAG_WITH_V=`git describe --abbrev=0 --tags ${CIRCLE_SHA1}` &&
          LATEST_TAG=${LATEST_TAG_WITH_V:1} &&
          IMAGE_NAME_APPROVED=snyk/kubernetes-monitor:${LATEST_TAG}-approved &&
          IMAGE_NAME_PUBLISHED=snyk/kubernetes-monitor:${LATEST_TAG} &&
          docker login --username ${DOCKERHUB_USER} --password ${DOCKERHUB_PASSWORD} &&
          docker pull ${IMAGE_NAME_APPROVED} &&
          docker tag ${IMAGE_NAME_APPROVED} ${IMAGE_NAME_PUBLISHED} &&
          docker push ${IMAGE_NAME_PUBLISHED} &&
          ./scripts/slack/notify_push.py ${IMAGE_NAME_PUBLISHED} &&
          ./scripts/publish-gh-pages.sh ${LATEST_TAG}
          # Preserve the latest tag for the next steps of this job
          echo "export LATEST_TAG=${LATEST_TAG}" >> $BASH_ENV
        name: Publish
    - run:
        command: |
          RELEASE_VERSION=v0.15.1
          DOWNLOAD_LOCATION=./operator-sdk
          CURL_FOLLOW_REDIRECTS="-L"
          curl ${CURL_FOLLOW_REDIRECTS} https://github.com/operator-framework/operator-sdk/releases/download/${RELEASE_VERSION}/operator-sdk-${RELEASE_VERSION}-x86_64-linux-gnu -o ${DOWNLOAD_LOCATION}
          chmod +x ${DOWNLOAD_LOCATION}
        name: Download operator-sdk
    - run:
        command: |
          ./scripts/operator/create-operator-and-push.sh "${LATEST_TAG}"
        name: Create Operator and push Operator image to DockerHub
    - run:
        command: |
          export SNYK_MONITOR_IMAGE_TAG="${LATEST_TAG}"
          export SNYK_OPERATOR_VERSION="${LATEST_TAG}"
          export SNYK_OPERATOR_IMAGE_TAG="${SNYK_MONITOR_IMAGE_TAG}"
          ./scripts/operator/package-operator.sh "${SNYK_OPERATOR_VERSION}" "${SNYK_OPERATOR_IMAGE_TAG}" "${SNYK_MONITOR_IMAGE_TAG}"
        name: Package Operator
    - run:
        command: |
          rm -rf snyk-operator/deploy/olm-catalog/snyk-operator/0.0.0
        name: Remove templated Operator before storing artifacts
    - store_artifacts:
        destination: snyk-operator
        path: snyk-operator/deploy/olm-catalog/snyk-operator
    - run:
        command: ./scripts/slack/notify_failure.py "master"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  push_operator_to_community_operators:
    description: |
      Packages a new Operator and pushes it to Snyk's fork of
      the OpenShift community-operators.
    executor: redhat-openshift/default
    steps:
    - checkout
    - add_ssh_keys:
        fingerprints:
        - 06:c3:d4:10:0d:ef:37:6c:ec:b9:fb:6e:ed:09:e7:40
    - run:
        command: |
          python -m pip install requests pyyaml
        name: Install required packages
    - install_python_requests
    - run:
        command: |
          set -xeo pipefail
          LAST_OPERATOR_VERSION=$(python ./scripts/operator/get-last-published-operator-version.py)
          echo "export LAST_OPERATOR_VERSION=${LAST_OPERATOR_VERSION}" >> $BASH_ENV
        name: Get last released Operator version
    - run:
        command: |
          LATEST_TAG_WITH_V=`git describe --abbrev=0 --tags ${CIRCLE_SHA1}`
          LATEST_TAG=${LATEST_TAG_WITH_V:1}
          NEW_OPERATOR_VERSION=${LATEST_TAG}
          echo "export NEW_OPERATOR_VERSION=${NEW_OPERATOR_VERSION}" >> $BASH_ENV
        name: Get new Operator version
    - run:
        command: |
          ./scripts/operator/package-operator.sh "${NEW_OPERATOR_VERSION}" "${NEW_OPERATOR_VERSION}" "${NEW_OPERATOR_VERSION}" "${LAST_OPERATOR_VERSION}"
        name: Package Operator
    - run:
        command: |
          set -xeo pipefail

          CURRENT_DIRECTORY=$(pwd)
          COMMUNITY_OPERATORS_UPSTREAM_LOCATION="${CURRENT_DIRECTORY}/community-operators"
          DEPLOY_LOCATION="${COMMUNITY_OPERATORS_UPSTREAM_LOCATION}/community-operators"
          OPERATOR_LOCATION="${CURRENT_DIRECTORY}/snyk-operator/deploy/olm-catalog/snyk-operator"

          # Configure git user and gpg key
          echo "${OPENSHIFT_OPERATOR_SIGNING_KEY_BASE64}" | base64 -d | gpg --import
          git config --global commit.gpgsign true
          git config --global user.signingkey "${OPENSHIFT_OPERATOR_SIGNING_KEY_ID}"
          git config --global user.email "${OPENSHIFT_OPERATOR_GITHUB_EMAIL}"
          git config --global user.name "${OPENSHIFT_OPERATOR_GITHUB_NAME}"

          # Clone Community Operators repo from Snyk
          git clone https://github.com/snyk/community-operators.git $COMMUNITY_OPERATORS_UPSTREAM_LOCATION
          cd "${COMMUNITY_OPERATORS_UPSTREAM_LOCATION}"
          git checkout -b snyk/snyk-operator-v${NEW_OPERATOR_VERSION}

          # Copy new release to branch
          cp -r "${OPERATOR_LOCATION}/${NEW_OPERATOR_VERSION}" "${DEPLOY_LOCATION}/snyk-operator/."
          cp "${OPERATOR_LOCATION}/snyk-operator.package.yaml" "${DEPLOY_LOCATION}/snyk-operator/."

          # Create the signed commit and push
          git add "${DEPLOY_LOCATION}/snyk-operator/*"
          git commit -s -m "Upgrade snyk-operator to version ${NEW_OPERATOR_VERSION}"
          git push --set-upstream origin --force snyk/snyk-operator-v${NEW_OPERATOR_VERSION}
        name: Open GitHub pull request to community-operators repository
    - run:
        command: ./scripts/slack/notify_failure.py "push-new-operator"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  system_tests:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - setup_node12
    - install_python_requests
    - run:
        command: |
          npm run build &&
          npm run test:system
        name: System tests
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-system-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  tag_and_push:
    docker:
    - image: circleci/node:12
    steps:
    - checkout
    - setup_remote_docker
    - install_python_requests
    - run:
        command: |
          npm install &&
          docker login --username ${DOCKERHUB_USER} --password ${DOCKERHUB_PASSWORD} &&
          unset CIRCLE_PULL_REQUEST &&
          unset CI_PULL_REQUEST &&
          unset CI_PULL_REQUESTS &&
          unset CIRCLE_PULL_REQUESTS &&
          npx semantic-release &&
          NEW_VERSION=`cat ./package.json | jq -r '.version'` &&
          ./scripts/docker/approve-image.sh $NEW_VERSION
        name: Tag and push
    - run:
        command: ./scripts/slack/notify_failure.py "staging-release"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  unit_tests:
    machine:
      docker_layer_caching: true
      enabled: true
    steps:
    - checkout
    - setup_node12
    - install_python_requests
    - run:
        command: |
          npm run lint &&
          npm run build &&
          npm run test:unit
        name: Unit tests
    - run:
        command: |
          ./scripts/slack/notify_failure_on_branch.py "staging-unit-tests-${CIRCLE_SHA1}"
        name: Notify Slack on failure
        when: on_fail
    working_directory: ~/kubernetes-monitor
  upload_operator:
    docker:
    - image: circleci/python:3
    steps:
    - attach_workspace:
        at: snyk-operator
    - run:
        command: pip3 install operator-courier
        name: Install operator-courier
    - run:
        command: |
          export QUAY_TOKEN=$(curl -H "Content-Type: application/json" -XPOST https://quay.io/cnr/api/v1/users/login -d "{\"user\": {\"username\": \"${QUAY_USERNAME}\", \"password\": \"${QUAY_PASSWORD}\"}}" | jq -r .token)
          export OPERATOR_DIR=./snyk-operator/deploy/olm-catalog/snyk-operator/
          export QUAY_NAMESPACE=snyk-runtime
          export PACKAGE_NAME=snyk-operator
          export PACKAGE_VERSION="0.0.1-${CIRCLE_SHA1}"
          operator-courier push "${OPERATOR_DIR}" "${QUAY_NAMESPACE}" "${PACKAGE_NAME}" "${PACKAGE_VERSION}" "${QUAY_TOKEN}"
        name: Upload Operator to Quay
    working_directory: ~/kubernetes-monitor
main_branches_filter:
  filters:
    branches:
      ignore:
      - staging
      - master
master_branch_only_filter:
  filters:
    branches:
      only:
      - master
orbs:
  redhat-openshift: circleci/redhat-openshift@0.2.0
staging_branch_only_filter:
  filters:
    branches:
      only:
      - staging
version: 2.1
workflows:
  MERGE_TO_MASTER:
    jobs:
    - publish:
        filters:
          branches:
            only:
            - master
    - deploy_prod:
        filters:
          branches:
            only:
            - master
        requires:
        - publish
  MERGE_TO_STAGING:
    jobs:
    - build_image:
        filters:
          branches:
            only:
            - staging
    - build_operator:
        filters:
          branches:
            only:
            - staging
    - upload_operator:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_operator
    - unit_tests:
        filters:
          branches:
            only:
            - staging
    - system_tests:
        filters:
          branches:
            only:
            - staging
    - integration_tests:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_image
    - integration_tests_helm:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_image
    - integration_tests_proxy:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_image
    - eks_integration_tests:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_image
    - openshift3_integration_tests:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_image
    - openshift4_integration_tests:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_image
        - build_operator
        - upload_operator
    - tag_and_push:
        filters:
          branches:
            only:
            - staging
        requires:
        - build_image
        - build_operator
        - unit_tests
        - system_tests
        - integration_tests
        - integration_tests_helm
        - integration_tests_proxy
    - deploy_dev:
        filters:
          branches:
            only:
            - staging
        requires:
        - tag_and_push
  NIGHTLY:
    jobs:
    - operator_upgrade_tests
    - push_operator_to_community_operators:
        requires:
        - operator_upgrade_tests
    triggers:
    - schedule:
        cron: 0 0 * * *
        filters:
          branches:
            only:
            - master
  PR_TO_STAGING:
    jobs:
    - build_image:
        filters:
          branches:
            ignore:
            - staging
            - master
    - build_operator:
        filters:
          branches:
            ignore:
            - staging
            - master
    - unit_tests:
        filters:
          branches:
            ignore:
            - staging
            - master
    - system_tests:
        filters:
          branches:
            ignore:
            - staging
            - master
    - integration_tests:
        filters:
          branches:
            ignore:
            - staging
            - master
        requires:
        - build_image
    - integration_tests_helm:
        filters:
          branches:
            ignore:
            - staging
            - master
        requires:
        - build_image
    - operator_upgrade_tests:
        filters:
          branches:
            only:
            - chore/overnight-operator-testing

